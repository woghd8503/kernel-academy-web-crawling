{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woghd8503/kernel-academy-web-crawling/blob/main/bsoup_fastcampus_starter(%ED%95%99%EC%83%9D%EC%9A%A9).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Qh3PLe-mA3"
      },
      "source": [
        "# BeautifulSoup 🥣\n",
        "\n",
        "안녕하세요! 이 노트북에서는 웹 페이지의 데이터를 가져오는 강력한 도구 중 하나인 **BeautifulSoup** 라이브러리의 기초 사용법을 배워봅니다. 웹 스크래핑 또는 웹 크롤링이라고도 불리는 이 기술은 웹사이트에서 원하는 정보를 추출하여 다양하게 활용할 수 있게 해줍니다.\n",
        "\n",
        "**학습 목표**\n",
        "1. HTML의 기본 구조 이해하기\n",
        "2. BeautifulSoup으로 HTML 문서를 파싱(parsing)하기\n",
        "3. 원하는 태그(tag)와 내용, 속성(attribute)을 찾는 방법 익히기\n",
        "\n",
        "---"
      ],
      "id": "z3Qh3PLe-mA3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcAfv9wq-mA5"
      },
      "source": [
        "## 1. HTML이란 무엇일까요? 🤔\n",
        "\n",
        "HTML(HyperText Markup Language)은 웹 페이지의 뼈대를 만드는 데 사용되는 언어입니다. 우리가 보는 웹사이트의 글자, 그림, 링크 등 모든 요소는 HTML 태그를 이용해 표현됩니다.\n",
        "\n",
        "예를 들어, 제목은 `<h1>`, 문단은 `<p>`, 링크는 `<a>` 태그를 사용합니다. 각 태그는 시작 태그(`<h1>`)와 종료 태그(`</h1>`)로 이루어지며, 그 사이에 내용이 들어갑니다. 때로는 태그 안에 '속성'이라는 추가 정보를 가질 수 있습니다. (예: `<a href=\"https://www.google.com\">구글</a>` 에서 `href`는 링크 주소를 나타내는 속성입니다.)\n",
        "\n",
        "BeautifulSoup은 바로 이 HTML 구조를 분석해서 우리가 원하는 정보를 쉽게 찾아낼 수 있도록 도와줍니다.\n",
        "\n",
        "**우리가 사용할 예제 HTML:**\n",
        "```html\n",
        "<html>\n",
        "<head>\n",
        "    <title>초보자를 위한 BeautifulSoup</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1 id=\"main-title\">웹 스크래핑 시작하기</h1>\n",
        "    <p class=\"content-text\">BeautifulSoup은 HTML과 XML 파일로부터 데이터를 뽑아내기 위한 파이썬 라이브러리입니다.</p>\n",
        "    <p class=\"content-text important\">사용하기 매우 간편해요!</p>\n",
        "    <div>\n",
        "        <a href=\"[https://www.crummy.com/software/BeautifulSoup/bs4/doc/](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\" class=\"bs-link\">공식 문서 보기</a>\n",
        "        <a href=\"[https://pypi.org/project/beautifulsoup4/](https://pypi.org/project/beautifulsoup4/)\" class=\"pypi-link\">PyPI 페이지</a>\n",
        "    </div>\n",
        "    <ul class=\"item-list\">\n",
        "        <li class=\"item\">첫 번째 아이템</li>\n",
        "        <li class=\"item\">두 번째 아이템</li>\n",
        "        <li class=\"item special\">세 번째 특별한 아이템</li>\n",
        "    </ul>\n",
        "</body>\n",
        "</html>\n",
        "```\n",
        "위 HTML 코드를 기반으로 실습을 진행할 것입니다. `requests` 라이브러리를 사용하지 않기 때문에, 위 HTML 코드를 직접 문자열로 만들어서 사용합니다.\n",
        "\n",
        "---"
      ],
      "id": "OcAfv9wq-mA5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf9ALbAd-mA5"
      },
      "source": [
        "## 2. BeautifulSoup 설치 및 HTML 파싱하기 🛠️\n",
        "\n",
        "먼저 `BeautifulSoup` 라이브러리를 설치해야 합니다. Colab 환경에는 대부분 기본적으로 설치되어 있지만, 로컬 환경에서 진행하셔서, 만약 설치되어 있지 않다면 아래 코드 셀의 주석을 해제하고 실행해주세요.\n",
        "\n",
        "설치 후에는 `bs4` 패키지에서 `BeautifulSoup` 클래스를 가져와(import) 사용합니다. 그리고 위에서 본 예제 HTML 문자열을 `BeautifulSoup` 객체로 만들어줍니다. 이때 어떤 파서(parser)를 사용할지 지정해야 하는데, 일반적으로 `html.parser`를 많이 사용합니다."
      ],
      "id": "Gf9ALbAd-mA5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPfGcvOQ-mA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6127cfc2-b838-4b3f-8272-c1d17cd17027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html>\n",
            " <head>\n",
            "  <title>\n",
            "   초보자를 위한 BeautifulSoup\n",
            "  </title>\n",
            " </head>\n",
            " <body>\n",
            "  <h1 id=\"main-title\">\n",
            "   웹 스크래핑 시작하기\n",
            "  </h1>\n",
            "  <p class=\"content-text\">\n",
            "   BeautifulSoup은 HTML과 XML 파일로부터 데이터를 뽑아내기 위한 파이썬 라이브러리입니다.\n",
            "  </p>\n",
            "  <p class=\"content-text important\">\n",
            "   사용하기 매우 간편해요!\n",
            "  </p>\n",
            "  <div>\n",
            "   <a class=\"bs-link\" href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">\n",
            "    공식 문서 보기\n",
            "   </a>\n",
            "   <a class=\"pypi-link\" href=\"https://pypi.org/project/beautifulsoup4/\">\n",
            "    PyPI 페이지\n",
            "   </a>\n",
            "  </div>\n",
            "  <ul class=\"item-list\">\n",
            "   <li class=\"item\">\n",
            "    첫 번째 아이템\n",
            "   </li>\n",
            "   <li class=\"item\">\n",
            "    두 번째 아이템\n",
            "   </li>\n",
            "   <li class=\"item special\">\n",
            "    세 번째 특별한 아이템\n",
            "   </li>\n",
            "  </ul>\n",
            " </body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !pip install beautifulsoup4 # Colab에 이미 설치되어 있다면 이 줄은 실행할 필요 없습니다.\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 분석할 HTML 문서 (문자열로 준비)\n",
        "html_doc = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        "    <title>초보자를 위한 BeautifulSoup</title>\n",
        "</head>\n",
        "<body>\n",
        "    <h1 id=\"main-title\">웹 스크래핑 시작하기</h1>\n",
        "    <p class=\"content-text\">BeautifulSoup은 HTML과 XML 파일로부터 데이터를 뽑아내기 위한 파이썬 라이브러리입니다.</p>\n",
        "    <p class=\"content-text important\">사용하기 매우 간편해요!</p>\n",
        "    <div>\n",
        "        <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\" class=\"bs-link\">공식 문서 보기</a>\n",
        "        <a href=\"https://pypi.org/project/beautifulsoup4/\" class=\"pypi-link\">PyPI 페이지</a>\n",
        "    </div>\n",
        "    <ul class=\"item-list\">\n",
        "        <li class=\"item\">첫 번째 아이템</li>\n",
        "        <li class=\"item\">두 번째 아이템</li>\n",
        "        <li class=\"item special\">세 번째 특별한 아이템</li>\n",
        "    </ul>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# BeautifulSoup 객체 생성 (HTML 파싱)\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "\n",
        "# 파싱된 HTML 구조 보기 (prettify()는 HTML 구조를 보기 좋게 만들어줍니다)\n",
        "print(soup.prettify())"
      ],
      "id": "WPfGcvOQ-mA6"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_UdAcT3YTmV"
      },
      "id": "K_UdAcT3YTmV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파싱된 HTML 구조 보기 (prettify()는 HTML 구조를 보기 좋게 만들어줍니다)\n",
        "print()"
      ],
      "metadata": {
        "id": "M-lj8exYYWQW"
      },
      "id": "M-lj8exYYWQW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cm4Jky_-mA6"
      },
      "source": [
        "---\n",
        "## 3. 태그(Tag) 찾기: `find()` 와 `find_all()` 🔎\n",
        "\n",
        "BeautifulSoup 객체가 만들어졌다면, 이제 원하는 HTML 요소를 찾을 수 있습니다.\n",
        "\n",
        "* `soup.find('태그이름')`: 해당 태그 중 **가장 먼저** 나오는 태그 하나를 반환합니다.\n",
        "* `soup.find_all('태그이름')`: 해당 태그 **모두**를 리스트 형태로 반환합니다.\n",
        "\n",
        "예를 들어, HTML 문서의 `<title>` 태그나 `<h1>` 태그를 찾아봅시다."
      ],
      "id": "2cm4Jky_-mA6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz4N4BkQ-mA6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9deb9abf-a84d-40af-8691-e4efc1dbb14a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title 태그: <title>초보자를 위한 BeautifulSoup</title>\n",
            "Title 태그: <title>초보자를 위한 BeautifulSoup</title>\n"
          ]
        }
      ],
      "source": [
        "# <title> 태그 찾기\n",
        "title_tag = soup.find('title')\n",
        "print(f\"Title 태그: {title_tag}\")"
      ],
      "id": "Mz4N4BkQ-mA6"
    },
    {
      "cell_type": "code",
      "source": [
        "# <h1> 태그 찾기\n",
        "h1_tag = soup.find('h1')\n",
        "print(f\"H1 태그: {h1_tag}\")"
      ],
      "metadata": {
        "id": "w6cAvV42argA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241cc01c-0d14-479a-acc5-ddb5fa0a62fc"
      },
      "id": "w6cAvV42argA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H1 태그: <h1 id=\"main-title\">웹 스크래핑 시작하기</h1>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lh3mC2vdO9X",
        "outputId": "36a9a03c-aebc-488c-dada-abd4a2f04f64"
      },
      "id": "1Lh3mC2vdO9X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<p class=\"content-text\">BeautifulSoup은 HTML과 XML 파일로부터 데이터를 뽑아내기 위한 파이썬 라이브러리입니다.</p>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <p> 태그 모두 찾기\n",
        "p_tags = soup.find_all('p')\n",
        "print(f\"\\n총 {len(p_tags)}개의 P 태그를 찾았습니다.\")\n",
        "for p in p_tags:\n",
        "    print(p)\n",
        "\n",
        "# <h1> 태그 모두 찾기\n",
        "h1_tags = soup.find_all('h1')\n",
        "print(f\"\\n총 {len(h1_tags)}개의 h1 태그를 찾았습니다.\")\n",
        "for h1 in h1_tags:\n",
        "    print(h1)"
      ],
      "metadata": {
        "id": "t1B1z2qCarUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3ec6d4-4e7b-4a9a-ef30-d9115c8dc652"
      },
      "id": "t1B1z2qCarUQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "총 2개의 P 태그를 찾았습니다.\n",
            "<p class=\"content-text\">BeautifulSoup은 HTML과 XML 파일로부터 데이터를 뽑아내기 위한 파이썬 라이브러리입니다.</p>\n",
            "<p class=\"content-text important\">사용하기 매우 간편해요!</p>\n",
            "\n",
            "총 1개의 h1 태그를 찾았습니다.\n",
            "<h1 id=\"main-title\">웹 스크래핑 시작하기</h1>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = str(h1_tag) # find\n",
        "print(t.split('<'))\n",
        "t = str(h1_tags) # find all 로 찾음\n",
        "print(t.split('<'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbLfjqrnd4Mk",
        "outputId": "e78b02c5-273b-40fd-cf5f-b2a777b0fac9"
      },
      "id": "VbLfjqrnd4Mk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'h1 id=\"main-title\">웹 스크래핑 시작하기', '/h1>']\n",
            "['[', 'h1 id=\"main-title\">웹 스크래핑 시작하기', '/h1>]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('h1'),soup.h1\n",
        "# 결론 : 같다 , 현재 상황에선 같다 (처음에 등장하는 h1태그를 찾고자 할 때는 같다. )\n",
        "# 하지만, find 기능 자체는 하나만 찾는것만 존재하는게 아니라, 다른 attribute값을 가진 h1을 찾고 싶다거나, 반복해서 다른 h1을 찾고 싶을땐,\n",
        "# find 기능을 확장해서 쓸수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV34-0r5lWlD",
        "outputId": "e42723b5-1ddb-43f7-c014-b6faedf33d44"
      },
      "id": "yV34-0r5lWlD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<h1 id=\"main-title\">웹 스크래핑 시작하기</h1>, <h1 id=\"main-title\">웹 스크래핑 시작하기</h1>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEzfifND-mA7"
      },
      "source": [
        "---\n",
        "## 4. 태그 안의 내용(text)과 속성(attributes) 가져오기 📝🔗\n",
        "\n",
        "태그를 찾았다면, 그 안의 텍스트 내용이나 태그가 가진 속성 값을 가져올 수 있습니다.\n",
        "\n",
        "* **텍스트 내용**: `태그.string` 또는 `태그.get_text()`\n",
        "    * `.string`: 태그 안에 정확히 문자열만 있을 때 사용합니다. (자식 태그가 더 있으면 `None`을 반환할 수 있습니다.)\n",
        "    * `.get_text()`: 태그 안의 모든 텍스트 조각을 합쳐서 반환합니다. (더 일반적으로 사용됩니다.)\n",
        "* **속성 값**: `태그['속성이름']` 또는 `태그.get('속성이름')`\n",
        "    * 예: `a_tag['href']`는 `<a>` 태그의 `href` 속성 값을 가져옵니다.\n",
        "\n",
        "앞서 찾은 `<h1>` 태그의 텍스트 내용과 첫 번째 `<a>` 태그의 `href` 속성 값을 가져와 봅시다."
      ],
      "id": "GEzfifND-mA7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGZTa1sV-mA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc1e945-be13-4d29-969e-c2113adb9ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H1 태그의 내용 (string): 웹 스크래핑 시작하기\n",
            "H1 태그의 내용 (get_text()): 웹 스크래핑 시작하기\n"
          ]
        }
      ],
      "source": [
        "# h1 태그의 텍스트 내용 가져오기\n",
        "h1_tag = soup.find('h1') # 위에서 이미 찾았지만, 복습 차원에서 다시 찾아봅니다.\n",
        "if h1_tag:\n",
        "    print(f\"H1 태그의 내용 (string): {h1_tag.string}\")\n",
        "    print(f\"H1 태그의 내용 (get_text()): {h1_tag.get_text()}\")"
      ],
      "id": "sGZTa1sV-mA7"
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 <p> 태그의 내용 가져오기\n",
        "first_p_tag = soup.find('p')\n",
        "if first_p_tag:\n",
        "    print(f\"\\n첫 번째 P 태그 내용: {first_p_tag}\")"
      ],
      "metadata": {
        "id": "2_ob3lYlatil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60581290-d4b7-4172-8b59-3b840bedde66"
      },
      "id": "2_ob3lYlatil",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "첫 번째 P 태그 내용: <p class=\"content-text\">BeautifulSoup은 HTML과 XML 파일로부터 데이터를 뽑아내기 위한 파이썬 라이브러리입니다.</p>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 <a> 태그의 href 속성 값 가져오기\n",
        "first_a_tag = soup.find('a')\n",
        "if first_a_tag:\n",
        "    print(f\"\\n첫 번째 A 태그의 href: {first_a_tag['href']}\")\n",
        "    print(f\"첫 번째 A 태그의 텍스트: {first_a_tag.get_text()}\")\n",
        "    print(first_a_tag['class'])"
      ],
      "metadata": {
        "id": "kQ-qxDpUautV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d60b8e-fd7c-467b-d70f-5de228ea5013"
      },
      "id": "kQ-qxDpUautV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "첫 번째 A 태그의 href: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
            "첫 번째 A 태그의 텍스트: 공식 문서 보기\n",
            "['bs-link']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk0RE2UY-mA7"
      },
      "source": [
        "---\n",
        "## 5. 특정 속성을 가진 태그 찾기 (class, id 등) ✨\n",
        "\n",
        "많은 HTML 태그들은 `class`나 `id` 같은 속성을 가집니다. 이를 이용해 더 정확하게 원하는 태그를 찾을 수 있습니다.\n",
        "\n",
        "* `id`로 찾기: `soup.find(id='아이디값')` (id는 보통 페이지 내에서 고유합니다)\n",
        "* `class`로 찾기: `soup.find_all(class_='클래스값')` (class는 여러 태그가 공유할 수 있습니다. `class_` 처럼 뒤에 언더스코어(`_`)를 붙이는 이유는 파이썬에서 `class`가 예약어이기 때문입니다.)\n",
        "* 다른 속성으로 찾기: `soup.find_all(attrs={'속성이름': '속성값'})`\n",
        "\n",
        "예제 HTML에서 `id`가 `main-title`인 태그와 `class`가 `content-text`인 모든 태그, 그리고 `class`가 `item`인 `<li>` 태그들을 찾아봅시다."
      ],
      "id": "uk0RE2UY-mA7"
    },
    {
      "cell_type": "code",
      "source": [
        "# id로 태그 찾기\n",
        "main_title = soup.find(id='main-title')\n",
        "if main_title:\n",
        "    print(f\"ID가 'main-title'인 태그: {main_title.get_text()}\")"
      ],
      "metadata": {
        "id": "Be2G308LawfF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fce25ba-49d9-48f5-c485-0ceead32f660"
      },
      "id": "Be2G308LawfF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID가 'main-title'인 태그: 웹 스크래핑 시작하기\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class로 태그 찾기\n",
        "content_texts = soup.find_all(class_ = 'content-text')\n",
        "print(f\"\\nClass가 'content-text'인 P 태그들:\")\n",
        "for ct in content_texts:\n",
        "    print(f\"- {ct.get_text()}\")"
      ],
      "metadata": {
        "id": "JfNGBUPMaxkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b25821c-afa7-4444-8df6-78146e28f6ba"
      },
      "id": "JfNGBUPMaxkX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class가 'content-text'인 P 태그들:\n",
            "- BeautifulSoup은 HTML과 XML 파일로부터 데이터를 뽑아내기 위한 파이썬 라이브러리입니다.\n",
            "- 사용하기 매우 간편해요!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 태그이면서 특정 class인 요소 찾기\n",
        "list_items = soup.find_all('li', class_='item') # <li> 태그 중 class가 'item'인 것들\n",
        "print(f\"\\nClass가 'item'인 LI 태그들:\")\n",
        "for item in list_items:\n",
        "    print(f\"- {item.get_text()}\")"
      ],
      "metadata": {
        "id": "aFVln1s_axgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9058d104-631b-4128-e672-59780e2b3448"
      },
      "id": "aFVln1s_axgb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class가 'item'인 LI 태그들:\n",
            "- 첫 번째 아이템\n",
            "- 두 번째 아이템\n",
            "- 세 번째 특별한 아이템\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 여러 class 중 하나를 가진 요소 찾기 (예: 'item' 이면서 'special' 클래스를 모두 가진 li)\n",
        "# BeautifulSoup은 find_all(class_=['item', 'special']) 과 같이 여러 클래스를 직접 AND 조건으로 찾기 어렵습니다.\n",
        "# 대신 CSS 선택자를 사용하거나 (다음 단계에서 배울 수 있음), 찾은 후 파이썬 코드로 필터링합니다.\n",
        "# 여기서는 class 속성 문자열에 'special'이 포함된 경우를 찾아봅시다.\n",
        "special_item = soup.find('li' , class_='special') # 'item'과 'special' 클래스 둘 다 가짐\n",
        "if special_item:\n",
        "    print(f\"\\nClass에 'special'이 포함된 LI 태그: {special_item.get_text()}\")"
      ],
      "metadata": {
        "id": "polOJKZhaxXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8ce5de-f54e-45c6-d83e-28e734efb1d1"
      },
      "id": "polOJKZhaxXA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class에 'special'이 포함된 LI 태그: 세 번째 특별한 아이템\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 속성으로 a 태그 찾기\n",
        "pypi_link = soup.find('a', attrs={'href': 'https://pypi.org/project/beautifulsoup4/'})\n",
        "if pypi_link:\n",
        "    print(f\"\\nPyPI 링크 A 태그: {pypi_link.get_text()})\")"
      ],
      "metadata": {
        "id": "02MZQVV4axPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f35fb26-ab50-4f99-85e0-84c7c3254dd8"
      },
      "id": "02MZQVV4axPA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PyPI 링크 A 태그: PyPI 페이지)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3fB73KU-mA8"
      },
      "source": [
        "---\n",
        "## 6. 정리 및 다음 단계 🚀\n",
        "\n",
        "축하합니다! BeautifulSoup의 기본적인 사용법을 익혔습니다. 오늘 배운 내용을 요약하면 다음과 같습니다:\n",
        "\n",
        "1.  `BeautifulSoup(html_문자열, 'html.parser')`로 HTML을 파싱합니다.\n",
        "2.  `soup.find()`와 `soup.find_all()`을 사용하여 원하는 태그를 찾습니다.\n",
        "3.  찾은 태그에서 `.get_text()`로 내용을, `태그['속성이름']`으로 속성 값을 가져옵니다.\n",
        "4.  `id`나 `class_` 같은 특정 속성을 기준으로 태그를 더 정확하게 찾을 수 있습니다.\n",
        "\n",
        "**다음 단계에서는 이런 것들을 더 배울 수 있습니다**\n",
        "\n",
        "* CSS 선택자(Selector)를 이용한 요소 검색 (매우 강력합니다! 예: `soup.select('div > p.some_class')`)\n",
        "* 웹사이트에서 직접 HTML을 가져오기 (`requests` 라이브러리 사용)\n",
        "* 더 복잡한 HTML 구조 탐색 (부모, 자식, 형제 태그 이동 등)\n",
        "* 추출한 데이터를 파일(CSV, Excel 등)로 저장하기\n",
        "\n",
        "연습만이 실력 향상의 지름길입니다! 다양한 웹사이트의 HTML 구조를 살펴보고, 오늘 배운 내용으로 간단한 정보들을 추출해보세요. 😊"
      ],
      "id": "H3fB73KU-mA8"
    }
  ]
}